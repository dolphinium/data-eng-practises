[2024-10-13T13:00:39.912+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-10-13T13:00:38.984612+00:00 [queued]>
[2024-10-13T13:00:39.916+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-10-13T13:00:38.984612+00:00 [queued]>
[2024-10-13T13:00:39.916+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 1
[2024-10-13T13:00:39.921+0000] {taskinstance.py:1380} INFO - Executing <Task(PythonOperator): reddit_extraction> on 2024-10-13 13:00:38.984612+00:00
[2024-10-13T13:00:39.923+0000] {standard_task_runner.py:57} INFO - Started process 59 to run task
[2024-10-13T13:00:39.925+0000] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'etl_reddit_pipeline', 'reddit_extraction', 'manual__2024-10-13T13:00:38.984612+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/reddit_dag.py', '--cfg-path', '/tmp/tmp3h4zc6zs']
[2024-10-13T13:00:39.925+0000] {standard_task_runner.py:85} INFO - Job 8: Subtask reddit_extraction
[2024-10-13T13:00:39.942+0000] {task_command.py:415} INFO - Running <TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-10-13T13:00:38.984612+00:00 [running]> on host f28f66444a85
[2024-10-13T13:00:39.971+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Yunus Emre KORKMAZ' AIRFLOW_CTX_DAG_ID='etl_reddit_pipeline' AIRFLOW_CTX_TASK_ID='reddit_extraction' AIRFLOW_CTX_EXECUTION_DATE='2024-10-13T13:00:38.984612+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-10-13T13:00:38.984612+00:00'
[2024-10-13T13:00:39.972+0000] {logging_mixin.py:151} INFO - connected to reddit!
[2024-10-13T13:00:41.049+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Do you already have tools in the industry m, that are working well for data quality? Not in my company, it seems that everything is scattered across many products. Looking for engineers and data leaders to have a conversation on how people manage DQ today, and what might be better ways?', 'author_fullname': 't2_7qt15uzx', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Survey: What tools are your companies using for data quality?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g2hcd3', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.96, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 38, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 38, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728791942.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Do you already have tools in the industry m, that are working well for data quality? Not in my company, it seems that everything is scattered across many products. Looking for engineers and data leaders to have a conversation on how people manage DQ today, and what might be better ways?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1g2hcd3', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Hefty-Present743'), 'discussion_type': None, 'num_comments': 35, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1g2hcd3/survey_what_tools_are_your_companies_using_for/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g2hcd3/survey_what_tools_are_your_companies_using_for/', 'subreddit_subscribers': 220318, 'created_utc': 1728791942.0, 'num_crossposts': 1, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.050+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Who went to dbt coalesce this year and what were your thoughts? I went to 10-12 talks over 2 days and only 2 of them were useful — one about incremental model efficiency/costs, and the other about 2 cool macros a team designed (one was a primary key/nullness test only on new data for incremental models, the other was a macro that identified unqueried models). The rest of them felt like “yeah we used to not use dbt and now we use dbt. Thanks for coming to my talk”', 'author_fullname': 't2_7ec0q', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Thoughts on dbt Coalesce this year?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g22a3o', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.97, 'author_flair_background_color': 'transparent', 'subreddit_type': 'public', 'ups': 31, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': 'fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b', 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 31, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728746019.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Who went to dbt coalesce this year and what were your thoughts? I went to 10-12 talks over 2 days and only 2 of them were useful — one about incremental model efficiency/costs, and the other about 2 cool macros a team designed (one was a primary key/nullness test only on new data for incremental models, the other was a macro that identified unqueried models). The rest of them felt like “yeah we used to not use dbt and now we use dbt. Thanks for coming to my talk”</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': 'Data Engineer', 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1g22a3o', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='mistanervous'), 'discussion_type': None, 'num_comments': 17, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': 'dark', 'permalink': '/r/dataengineering/comments/1g22a3o/thoughts_on_dbt_coalesce_this_year/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g22a3o/thoughts_on_dbt_coalesce_this_year/', 'subreddit_subscribers': 220318, 'created_utc': 1728746019.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.051+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': '\nI just saw a job post essentially requiring you to join a team that build the company’s data platform from scratch. Even though I consider myself somewhat decent experienced, I still find myself feeling uncomfortable with this kind of demand. I wonder what do others feel about it?', 'author_fullname': 't2_k0g7i3t63', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How many years of experience is needed to build a data platform from scratch?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g25nl3', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.78, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 26, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 26, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728755370.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I just saw a job post essentially requiring you to join a team that build the company’s data platform from scratch. Even though I consider myself somewhat decent experienced, I still find myself feeling uncomfortable with this kind of demand. I wonder what do others feel about it?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1g25nl3', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Zestyclose-Sun-2684'), 'discussion_type': None, 'num_comments': 26, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1g25nl3/how_many_years_of_experience_is_needed_to_build_a/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g25nl3/how_many_years_of_experience_is_needed_to_build_a/', 'subreddit_subscribers': 220318, 'created_utc': 1728755370.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.052+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Ok, title of this post is a gross oversimplification, but basically I\'m facing a situation where I\'m torn between two competing offers from very different companies. Each have very distinct pros and cons.\n\nBoth roles are fully remote and are offering similar compensation and benefits. For context I\'m a DE with ~4 YOE looking for senior roles.\n\n# Company A - the "good vibes" company\n* Large nonprofit with a fantastic reputation for employee wellbeing and career stability. Got great vibes from their hiring process\n* Old organization with a lot of technical debt and poor developer practices from what I could gather from the meeting the team. Many people who have been there for decades and aren\'t up to date on changes in the industry.\n* Job title is wack - "Senior Python Data Analytics Program Developer"\n\n# Company B - the "mixed vibes" company\n* Huge multinational consulting firm with a so-so repuation for employee wellbeing and career stability. Got mixed vibes from their hiring process. Feels extremely corporate in a bad way\n* Felt pretty micro-managey - DEs work in highly structured scrum teams, lots of layers of middle management, less flexible on working hours\n* On the plus side, their developer teams seem very proficient. Has a unified tech stack using modern tools (spark, dbt etc.), following software engineering best practices, better collaboration across teams with data scientists and SEs.\n* Senior Data Engineer job title\n\nSo based on vibes alone, I feel a lot more comfortable with Company A. But I worry that I\'ll have less opportunities for growth at a company with such antiquated tech, and I might have to supplement my career by self studying on the side to keep up with industry best practices. If anyone here has gone through a similar decision I would really appreciate the insight', 'author_fullname': 't2_1xtk67f5', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Thoughts on low-tech job at a "great vibes" company vs. high-tech job at a "mixed vibes" company', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g276w2', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.92, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 25, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 25, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728759588.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Ok, title of this post is a gross oversimplification, but basically I&#39;m facing a situation where I&#39;m torn between two competing offers from very different companies. Each have very distinct pros and cons.</p>\n\n<p>Both roles are fully remote and are offering similar compensation and benefits. For context I&#39;m a DE with ~4 YOE looking for senior roles.</p>\n\n<h1>Company A - the &quot;good vibes&quot; company</h1>\n\n<ul>\n<li>Large nonprofit with a fantastic reputation for employee wellbeing and career stability. Got great vibes from their hiring process</li>\n<li>Old organization with a lot of technical debt and poor developer practices from what I could gather from the meeting the team. Many people who have been there for decades and aren&#39;t up to date on changes in the industry.</li>\n<li>Job title is wack - &quot;Senior Python Data Analytics Program Developer&quot;</li>\n</ul>\n\n<h1>Company B - the &quot;mixed vibes&quot; company</h1>\n\n<ul>\n<li>Huge multinational consulting firm with a so-so repuation for employee wellbeing and career stability. Got mixed vibes from their hiring process. Feels extremely corporate in a bad way</li>\n<li>Felt pretty micro-managey - DEs work in highly structured scrum teams, lots of layers of middle management, less flexible on working hours</li>\n<li>On the plus side, their developer teams seem very proficient. Has a unified tech stack using modern tools (spark, dbt etc.), following software engineering best practices, better collaboration across teams with data scientists and SEs.</li>\n<li>Senior Data Engineer job title</li>\n</ul>\n\n<p>So based on vibes alone, I feel a lot more comfortable with Company A. But I worry that I&#39;ll have less opportunities for growth at a company with such antiquated tech, and I might have to supplement my career by self studying on the side to keep up with industry best practices. If anyone here has gone through a similar decision I would really appreciate the insight</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1g276w2', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='donhuell'), 'discussion_type': None, 'num_comments': 55, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1g276w2/thoughts_on_lowtech_job_at_a_great_vibes_company/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g276w2/thoughts_on_lowtech_job_at_a_great_vibes_company/', 'subreddit_subscribers': 220318, 'created_utc': 1728759588.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.052+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "What's your method for versionig data?", 'author_fullname': 't2_14y6gjhjkd', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How do you implement Slowly Changing Dimensions?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g1z3y4', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.84, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 24, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 24, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728736367.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>What&#39;s your method for versionig data?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1g1z3y4', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Temporary_Basil_7801'), 'discussion_type': None, 'num_comments': 19, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1g1z3y4/how_do_you_implement_slowly_changing_dimensions/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g1z3y4/how_do_you_implement_slowly_changing_dimensions/', 'subreddit_subscribers': 220318, 'created_utc': 1728736367.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.053+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I made a few scripts to get data from different apis for the company I work for, currently I'm running it local so I've just hardcoded the secrets\n\nthere seem to be a move toward running it on a server and running them on a cron, so I want to have a config file to store secrets and few configs there like certain path preferences and such.\n\nI'm considering using a .config file that will just be json, there's also dotenv that I've been reading about.\n\nand to make it even more fun, they will eventually move it to az (I wanted it to be in az from start but they didn't want it for some reason), but I guess I'll have to edit that code later to adjust for the change.\n\nWhat do you do at your company to have something that works both on local, server, and cloud?", 'author_fullname': 't2_7uzjthbm', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'how are you storing env variables? Python', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g22s44', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.87, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 23, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 23, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728747413.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I made a few scripts to get data from different apis for the company I work for, currently I&#39;m running it local so I&#39;ve just hardcoded the secrets</p>\n\n<p>there seem to be a move toward running it on a server and running them on a cron, so I want to have a config file to store secrets and few configs there like certain path preferences and such.</p>\n\n<p>I&#39;m considering using a .config file that will just be json, there&#39;s also dotenv that I&#39;ve been reading about.</p>\n\n<p>and to make it even more fun, they will eventually move it to az (I wanted it to be in az from start but they didn&#39;t want it for some reason), but I guess I&#39;ll have to edit that code later to adjust for the change.</p>\n\n<p>What do you do at your company to have something that works both on local, server, and cloud?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1g22s44', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='BigMickDo'), 'discussion_type': None, 'num_comments': 31, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1g22s44/how_are_you_storing_env_variables_python/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g22s44/how_are_you_storing_env_variables_python/', 'subreddit_subscribers': 220318, 'created_utc': 1728747413.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.054+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hey everyone,\n\nSo, after working as an Data Engineer for around 4+ years I received an proposal to join a consultancy company to work as an Data Architect. Since seemed to see a really good opportunity to step up my career I accepted the new challenge.\n\nHowever, after being in the position for a couple of months,  it seems that my currently responsibilities don't match with the role.\n\nCurrently I'm expected to:\n\n- Work as a team lead of data engineers, helping them during the execution of the project (in a technical and management way, like see what are the priorities and what should be done next)\n- Help the pre-sales team to pitch some architectures to future clients\n- Help the sales team to define the team allocation for a project and also the tasks that will be executed during the implementation phase (so they can calculate the price to make the proposal to the client)\n- Perform some funcional assessment on clients in terms of tasks that will be implemented after the architecture proposal \n- Perform the normal architect tasks (understand the need, design, prototyping, follow-up,, etc)\n\nFor me the architect position was only about the last point, we have a PM so in my mind those management activities should be under him (or a totally different position like an Sales Architect).\n\nSo, I would like to hear from you to align my expectations about the position and see if I got it wrong.", 'author_fullname': 't2_oui1s', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': "How your Data Architect daily job look like and what's the current expectations of your position?", 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g2c2rr', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.88, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 21, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 21, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728773852.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hey everyone,</p>\n\n<p>So, after working as an Data Engineer for around 4+ years I received an proposal to join a consultancy company to work as an Data Architect. Since seemed to see a really good opportunity to step up my career I accepted the new challenge.</p>\n\n<p>However, after being in the position for a couple of months,  it seems that my currently responsibilities don&#39;t match with the role.</p>\n\n<p>Currently I&#39;m expected to:</p>\n\n<ul>\n<li>Work as a team lead of data engineers, helping them during the execution of the project (in a technical and management way, like see what are the priorities and what should be done next)</li>\n<li>Help the pre-sales team to pitch some architectures to future clients</li>\n<li>Help the sales team to define the team allocation for a project and also the tasks that will be executed during the implementation phase (so they can calculate the price to make the proposal to the client)</li>\n<li>Perform some funcional assessment on clients in terms of tasks that will be implemented after the architecture proposal </li>\n<li>Perform the normal architect tasks (understand the need, design, prototyping, follow-up,, etc)</li>\n</ul>\n\n<p>For me the architect position was only about the last point, we have a PM so in my mind those management activities should be under him (or a totally different position like an Sales Architect).</p>\n\n<p>So, I would like to hear from you to align my expectations about the position and see if I got it wrong.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1g2c2rr', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Huntercorpse'), 'discussion_type': None, 'num_comments': 11, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1g2c2rr/how_your_data_architect_daily_job_look_like_and/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g2c2rr/how_your_data_architect_daily_job_look_like_and/', 'subreddit_subscribers': 220318, 'created_utc': 1728773852.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.054+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "A colleague thinks event-driven architecture (EDA) is a silver bullet for everything. He is a software engineer by trade and has used EDA successfully for application integration. He claims that EDA can be the end-all for sharing data, including for analytics needs. I'm skeptical but not closed to the idea. \n\nEDA is a reasonable approach for capturing immutable data (write once or append-only, like click stream data) for analytics. However, use cases can be more sophisticated in an analytics environment, say a data warehouse. For example, in an RDBMS table, tracking state changes at the source record level. In other words, where tracking record-level state changes based on the columns in a record is required. Now, one could design an EDA framework to broadcast record-level state changes, but wouldn't this be the same as standard CDC event sourcing and application of said CDC to the analytics target table?\n\nWhat is your experience? What other challenges do you see trying to use EDA as an end-all solution for analytics use cases? Or perhaps you agree with my colleague!\n\nThanks in advance for any thoughts you can share.", 'author_fullname': 't2_ems79i53', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'event-driven architecture for analytics data acquisition', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g2h3i7', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.83, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 10, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 10, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728791022.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>A colleague thinks event-driven architecture (EDA) is a silver bullet for everything. He is a software engineer by trade and has used EDA successfully for application integration. He claims that EDA can be the end-all for sharing data, including for analytics needs. I&#39;m skeptical but not closed to the idea. </p>\n\n<p>EDA is a reasonable approach for capturing immutable data (write once or append-only, like click stream data) for analytics. However, use cases can be more sophisticated in an analytics environment, say a data warehouse. For example, in an RDBMS table, tracking state changes at the source record level. In other words, where tracking record-level state changes based on the columns in a record is required. Now, one could design an EDA framework to broadcast record-level state changes, but wouldn&#39;t this be the same as standard CDC event sourcing and application of said CDC to the analytics target table?</p>\n\n<p>What is your experience? What other challenges do you see trying to use EDA as an end-all solution for analytics use cases? Or perhaps you agree with my colleague!</p>\n\n<p>Thanks in advance for any thoughts you can share.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1g2h3i7', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='OneWoodpecker8697'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1g2h3i7/eventdriven_architecture_for_analytics_data/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g2h3i7/eventdriven_architecture_for_analytics_data/', 'subreddit_subscribers': 220318, 'created_utc': 1728791022.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.055+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi all, \n\nI am currently working with GCP, Big Query and GitHub. \n\nI have a repo with 5 sql scripts that I want to run in a specific order on a monthly basis.\n\nI have not seen instances of how to create a DAG using code directly from the repo and calling the scripts but instead creating a seperate repo for the DAG, but I want to just use the original repo to avoid duplication. \n\nPlease let me know if you have any experience or resources on this. \n\nThank you ', 'author_fullname': 't2_t6kbu5ets', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Creating a DAG to run a SQL pipeline from a GitHub Repo', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g2avrn', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.81, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728770134.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi all, </p>\n\n<p>I am currently working with GCP, Big Query and GitHub. </p>\n\n<p>I have a repo with 5 sql scripts that I want to run in a specific order on a monthly basis.</p>\n\n<p>I have not seen instances of how to create a DAG using code directly from the repo and calling the scripts but instead creating a seperate repo for the DAG, but I want to just use the original repo to avoid duplication. </p>\n\n<p>Please let me know if you have any experience or resources on this. </p>\n\n<p>Thank you </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1g2avrn', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Beautiful_Fuel5252'), 'discussion_type': None, 'num_comments': 20, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1g2avrn/creating_a_dag_to_run_a_sql_pipeline_from_a/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g2avrn/creating_a_dag_to_run_a_sql_pipeline_from_a/', 'subreddit_subscribers': 220318, 'created_utc': 1728770134.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.055+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'https://practicaldataengineering.substack.com/p/building-data-pipeline-using-duckdb', 'author_fullname': 't2_579zp4ag', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Building Data Pipelines with DuckDB', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g2kowm', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.83, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 7, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 7, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728806161.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p><a href="https://practicaldataengineering.substack.com/p/building-data-pipeline-using-duckdb">https://practicaldataengineering.substack.com/p/building-data-pipeline-using-duckdb</a></p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/9thSUAPF6yZZ4lxbL30T71F7GQApVBuQYiR06_tZOK4.jpg?auto=webp&s=b4899e702d8642153d3169e1992967f8a9796226', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/9thSUAPF6yZZ4lxbL30T71F7GQApVBuQYiR06_tZOK4.jpg?width=108&crop=smart&auto=webp&s=f1a78027b52146fbf48d645229aa0bd4ae5b0ed3', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/9thSUAPF6yZZ4lxbL30T71F7GQApVBuQYiR06_tZOK4.jpg?width=216&crop=smart&auto=webp&s=3e05b6563f0f56e6b8bdaff4fd2ebf8136d43638', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/9thSUAPF6yZZ4lxbL30T71F7GQApVBuQYiR06_tZOK4.jpg?width=320&crop=smart&auto=webp&s=573c1f783d083900f5e9d5990c55ca51a9e11a27', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/9thSUAPF6yZZ4lxbL30T71F7GQApVBuQYiR06_tZOK4.jpg?width=640&crop=smart&auto=webp&s=3ba7ea1737917965b5642eea3fcdc49fa6333504', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/9thSUAPF6yZZ4lxbL30T71F7GQApVBuQYiR06_tZOK4.jpg?width=960&crop=smart&auto=webp&s=635cb7eba07696968e69c3bcd200427eb2937964', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/9thSUAPF6yZZ4lxbL30T71F7GQApVBuQYiR06_tZOK4.jpg?width=1080&crop=smart&auto=webp&s=89870f171f747f78e64ba54a059a6bded0e9c78a', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'T4oS71jt8Jf5NIelUO7VRLyIrjQhgre8DVY0nFS5Gxs'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1g2kowm', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='ithoughtful'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1g2kowm/building_data_pipelines_with_duckdb/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g2kowm/building_data_pipelines_with_duckdb/', 'subreddit_subscribers': 220318, 'created_utc': 1728806161.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.056+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Little bit of a challenge question to spot check my own solutions, and to show how wide data engineering can be for newer folks.     \n  \nYou pickup a contract to build out a company\'s data warehouse. Its a smaller company, with 6 years worth of data. No data team, and an engineering team that doesn\'t have any data specialties.  \n  \nThey have a *** db as Prod, in Heroku, app is javascript in AWS. No hardware. \n\nTheir current internal proposed solution before hiring you, is: \n\nPostgres > Sync service > Snowflake > unsure (weighing Power Bi, Tableau, etc)\n\nBasic db structure in Postgres: \n \n    user    \n         name, username, id  \n    sessionData  \n         id, content_id, stuff  \n    sessionUserData  \n         id, user_id, sessionData_id, stuff  \n    content  \n         id, title, stuff\nand about 130 more tables. Stored Procedures abound in Prod. \n\nRequirements:   \n  \nThey want 3 end products.   \n  \n1_ A data "lake": that holds the raw data from Production   \n2_ Data "Mart" that contains transformed data from the lake, for various teams in the company.    \n3_ A BI system that allows internal team members to run defined reports, for any client in the system. (4 reports/dashboards/apps)   \n\nThey have to follow Federal rules, so security is a focus. Some team members will be allowed to see PII, others won\'t.   \n  \n\nHow would you build it? What services would you use? What\'s the project look like (length, cost, etc)? How many people?', 'author_fullname': 't2_17fxzdoz', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How would you approach the challenge?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g2h93v', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.86, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1728792489.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728791594.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Little bit of a challenge question to spot check my own solutions, and to show how wide data engineering can be for newer folks.     </p>\n\n<p>You pickup a contract to build out a company&#39;s data warehouse. Its a smaller company, with 6 years worth of data. No data team, and an engineering team that doesn&#39;t have any data specialties.  </p>\n\n<p>They have a *** db as Prod, in Heroku, app is javascript in AWS. No hardware. </p>\n\n<p>Their current internal proposed solution before hiring you, is: </p>\n\n<p>Postgres &gt; Sync service &gt; Snowflake &gt; unsure (weighing Power Bi, Tableau, etc)</p>\n\n<p>Basic db structure in Postgres: </p>\n\n<pre><code>user    \n     name, username, id  \nsessionData  \n     id, content_id, stuff  \nsessionUserData  \n     id, user_id, sessionData_id, stuff  \ncontent  \n     id, title, stuff\n</code></pre>\n\n<p>and about 130 more tables. Stored Procedures abound in Prod. </p>\n\n<p>Requirements:   </p>\n\n<p>They want 3 end products.   </p>\n\n<p>1_ A data &quot;lake&quot;: that holds the raw data from Production<br/>\n2_ Data &quot;Mart&quot; that contains transformed data from the lake, for various teams in the company.<br/>\n3_ A BI system that allows internal team members to run defined reports, for any client in the system. (4 reports/dashboards/apps)   </p>\n\n<p>They have to follow Federal rules, so security is a focus. Some team members will be allowed to see PII, others won&#39;t.   </p>\n\n<p>How would you build it? What services would you use? What&#39;s the project look like (length, cost, etc)? How many people?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1g2h93v', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='_00307'), 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1g2h93v/how_would_you_approach_the_challenge/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g2h93v/how_would_you_approach_the_challenge/', 'subreddit_subscribers': 220318, 'created_utc': 1728791594.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.056+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Same as above ', 'author_fullname': 't2_84ztczxp', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How can I use Spark for concurrent querying or as a distributed SQL engine?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g28c4v', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.76, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728762777.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Same as above </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1g28c4v', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='chaachans'), 'discussion_type': None, 'num_comments': 11, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1g28c4v/how_can_i_use_spark_for_concurrent_querying_or_as/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g28c4v/how_can_i_use_spark_for_concurrent_querying_or_as/', 'subreddit_subscribers': 220318, 'created_utc': 1728762777.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.057+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hello. \n\nRight now at our company we use a SSIS and SQL on prem solution. The problem is that some of the API we are using are annoying to use with SSIS and we are trying to leverage pythons simplicity. \n\nWe are now trying to setup some hybrid solution with Microsoft Fabric. So the use case would be use the lowest capacity (F2) and then python notebooks to extract data from the API, then store it in Lakehouse and move it to our on prem SQL server for further data modelling. \n\nDoes anybody have experience with this? I am just wondering how would we go about and orchestrate this, and can we somehow leverage the SQL agent scheduler like we do now the SSIS jobs. I can see there Microsoft has an API (in preview) that can call fabric notebooks and would like to hear if anybody has experiences with this. \n\nAdditionally we are also looking into moving our setup from SSIS packages to python and dbt and then using dagster as a service to orchestrate it. Would that make Fabric obsolete, or would it still be a way to leverage Fabric's scalability?  ", 'author_fullname': 't2_9pmpqaja', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Microsoft Fabric - And orchestration', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g2au1w', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728769988.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hello. </p>\n\n<p>Right now at our company we use a SSIS and SQL on prem solution. The problem is that some of the API we are using are annoying to use with SSIS and we are trying to leverage pythons simplicity. </p>\n\n<p>We are now trying to setup some hybrid solution with Microsoft Fabric. So the use case would be use the lowest capacity (F2) and then python notebooks to extract data from the API, then store it in Lakehouse and move it to our on prem SQL server for further data modelling. </p>\n\n<p>Does anybody have experience with this? I am just wondering how would we go about and orchestrate this, and can we somehow leverage the SQL agent scheduler like we do now the SSIS jobs. I can see there Microsoft has an API (in preview) that can call fabric notebooks and would like to hear if anybody has experiences with this. </p>\n\n<p>Additionally we are also looking into moving our setup from SSIS packages to python and dbt and then using dagster as a service to orchestrate it. Would that make Fabric obsolete, or would it still be a way to leverage Fabric&#39;s scalability?  </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1g2au1w', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='WestIndication5866'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1g2au1w/microsoft_fabric_and_orchestration/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g2au1w/microsoft_fabric_and_orchestration/', 'subreddit_subscribers': 220318, 'created_utc': 1728769988.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.057+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I’m moving into my first role where I’m the sole data engineer. I’m a bit nervous. Any advice or anecdotes for how to succeed are appreciated. ', 'author_fullname': 't2_98rrwspa', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Advice for first time solo DE?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g221i8', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': 'transparent', 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': 'fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b', 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728745341.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I’m moving into my first role where I’m the sole data engineer. I’m a bit nervous. Any advice or anecdotes for how to succeed are appreciated. </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': 'Data Engineer', 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1g221i8', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='what_duck'), 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': 'dark', 'permalink': '/r/dataengineering/comments/1g221i8/advice_for_first_time_solo_de/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g221i8/advice_for_first_time_solo_de/', 'subreddit_subscribers': 220318, 'created_utc': 1728745341.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.058+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I was recently offered a head data position at a promising startup. They need someone to connect their engineering and data science divisions to break the direct dependence engineering has on models and models have on engineering. This job would entail building that intermediary layer as well as being responsible for storing and retrieving of data (archival, transformations, etc.) They\'re in the space of document parsing and analysis, to put it generically. So many models involve OCR, data extraction, and then risk modelling.\n\nI currently work as a SWE at a small subcompany of an established financial services company. We have a lot of tech debt and not a ton of competent engineers. We are currently about to begin completely rebuilding our backend. I\'ve had my doubts about the technical leadership leading this effort. When I told my boss about this opportunity he offered to create a position of tech lead for the data team here, which doesn\'t yet exist. We have many of the same issues (connecting data science to Eng, data flow) but a different type of technical problem. We\'re essentially a stream processing company but we don\'t use any stream processing tools. This could be an opportunity to introduce Flink, Cassandra, and many other solutions we don\'t use in favor of "tools we know" that are really ill equipped for the work we do. We\'re a type of trading company: so the technical problem is a ton of data coming in at high speed that needs to be stored and retrieved at scale.\n\nThe compensation is effectively equal. I\'d be given equity in the startup but short-term my current company would likely pay more.\n\nAs I imagine the technical challenge would be:\n\n(Current company)\n- Create framework for non-savvy coders to write and deploy Beam pipelines to a Flink operator in our kubernetes cluster\n- use that framework to write Kafka-Kafka, Kafka-RedisStreams, Kafka-Cassandra, and Kafka-Blob pipelines for recording all the data through the system \n- write a DAL Python package that quants and model devs can use to easily access data \n- write an API that uses that DAL to surface data to UIs and front end applications\n\n(Startup)\n- using either AWS sagemaker or GCP Vertex AI, create a system where data scientists can write, train, and deploy models using notebooks to speed up iteration \n- create process by which data scientists can define DAGs of model inference based on incoming raw data in buckets\n- write a DAL Python package that model developers can use to easily access data\n- write an API for the front end app to use for data input and output that likely makes calls to the DAL package\n\nTo be reductive:\n- current company solves problems relating to enormously low latency high bandwidth data streaming, transforming, and inference. Because of corporate culture we can\'t use any cloud platform tools\n- startup company solves problems relating to extremely complex data analysis on ad-hoc document inputs, so much slower but with modern stack solutions\n\nSomeday I\'d like to start a startup in the same industry as my current company so I\'m torn. I\'ll learn more about the industry if I stay, but I\'ll learn more about a modern stack I\'d be more likely to use if I go\n\nI\'m having a ton of trouble deciding and my deadline is Monday. How would you go about evaluating which job to take?', 'author_fullname': 't2_861q7', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Choosing between jobs', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g2lvib', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.83, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1728812713.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728811600.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I was recently offered a head data position at a promising startup. They need someone to connect their engineering and data science divisions to break the direct dependence engineering has on models and models have on engineering. This job would entail building that intermediary layer as well as being responsible for storing and retrieving of data (archival, transformations, etc.) They&#39;re in the space of document parsing and analysis, to put it generically. So many models involve OCR, data extraction, and then risk modelling.</p>\n\n<p>I currently work as a SWE at a small subcompany of an established financial services company. We have a lot of tech debt and not a ton of competent engineers. We are currently about to begin completely rebuilding our backend. I&#39;ve had my doubts about the technical leadership leading this effort. When I told my boss about this opportunity he offered to create a position of tech lead for the data team here, which doesn&#39;t yet exist. We have many of the same issues (connecting data science to Eng, data flow) but a different type of technical problem. We&#39;re essentially a stream processing company but we don&#39;t use any stream processing tools. This could be an opportunity to introduce Flink, Cassandra, and many other solutions we don&#39;t use in favor of &quot;tools we know&quot; that are really ill equipped for the work we do. We&#39;re a type of trading company: so the technical problem is a ton of data coming in at high speed that needs to be stored and retrieved at scale.</p>\n\n<p>The compensation is effectively equal. I&#39;d be given equity in the startup but short-term my current company would likely pay more.</p>\n\n<p>As I imagine the technical challenge would be:</p>\n\n<p>(Current company)\n- Create framework for non-savvy coders to write and deploy Beam pipelines to a Flink operator in our kubernetes cluster\n- use that framework to write Kafka-Kafka, Kafka-RedisStreams, Kafka-Cassandra, and Kafka-Blob pipelines for recording all the data through the system \n- write a DAL Python package that quants and model devs can use to easily access data \n- write an API that uses that DAL to surface data to UIs and front end applications</p>\n\n<p>(Startup)\n- using either AWS sagemaker or GCP Vertex AI, create a system where data scientists can write, train, and deploy models using notebooks to speed up iteration \n- create process by which data scientists can define DAGs of model inference based on incoming raw data in buckets\n- write a DAL Python package that model developers can use to easily access data\n- write an API for the front end app to use for data input and output that likely makes calls to the DAL package</p>\n\n<p>To be reductive:\n- current company solves problems relating to enormously low latency high bandwidth data streaming, transforming, and inference. Because of corporate culture we can&#39;t use any cloud platform tools\n- startup company solves problems relating to extremely complex data analysis on ad-hoc document inputs, so much slower but with modern stack solutions</p>\n\n<p>Someday I&#39;d like to start a startup in the same industry as my current company so I&#39;m torn. I&#39;ll learn more about the industry if I stay, but I&#39;ll learn more about a modern stack I&#39;d be more likely to use if I go</p>\n\n<p>I&#39;m having a ton of trouble deciding and my deadline is Monday. How would you go about evaluating which job to take?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1g2lvib', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='shepzuck'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1g2lvib/choosing_between_jobs/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g2lvib/choosing_between_jobs/', 'subreddit_subscribers': 220318, 'created_utc': 1728811600.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.058+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hello Everyone,  I am currently preparing for sbowflake pro certification . Anyone suggest some best sources for learning it .', 'author_fullname': 't2_crpxkk3o', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Recommendation: Resources to prepare for Snowflake Pro Certification ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g2jhek', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728800699.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hello Everyone,  I am currently preparing for sbowflake pro certification . Anyone suggest some best sources for learning it .</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1g2jhek', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Used-Secret4741'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1g2jhek/recommendation_resources_to_prepare_for_snowflake/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g2jhek/recommendation_resources_to_prepare_for_snowflake/', 'subreddit_subscribers': 220318, 'created_utc': 1728800699.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.058+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hiya,\n\nYou are working full-time and exploring a switch, or currently looking for a job. Fully remote is preferred by many but not always an option. You see a job description that ticks off 70% of what you do so that means 30% of likely new things and potential growth, everything else is covered too like medical and pension, it has your name all over it!\n\nHowever, the office where you need to be 2-3 days a week, is 1h, 2h, 3h away from where you live.\n\nWould you consider applying for the job? And if you get hired, would you actually commit to the long travel?\n\nI'm trying to re-gauge my sense of work-life balance, whether it's too comfy or not taking care of myself enough, hoping for others to share their experiences and perspectives.\n\nHappy Sunday!", 'author_fullname': 't2_kh3ubtce', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How far would you be willing to travel for that dream DE job?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_1g2nrsd', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.5, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728819710.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hiya,</p>\n\n<p>You are working full-time and exploring a switch, or currently looking for a job. Fully remote is preferred by many but not always an option. You see a job description that ticks off 70% of what you do so that means 30% of likely new things and potential growth, everything else is covered too like medical and pension, it has your name all over it!</p>\n\n<p>However, the office where you need to be 2-3 days a week, is 1h, 2h, 3h away from where you live.</p>\n\n<p>Would you consider applying for the job? And if you get hired, would you actually commit to the long travel?</p>\n\n<p>I&#39;m trying to re-gauge my sense of work-life balance, whether it&#39;s too comfy or not taking care of myself enough, hoping for others to share their experiences and perspectives.</p>\n\n<p>Happy Sunday!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1g2nrsd', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='SquidsAndMartians'), 'discussion_type': None, 'num_comments': 5, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1g2nrsd/how_far_would_you_be_willing_to_travel_for_that/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g2nrsd/how_far_would_you_be_willing_to_travel_for_that/', 'subreddit_subscribers': 220318, 'created_utc': 1728819710.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.059+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I tend to immerse myself in theory, but I'm trying to shift my approach. How much theory is sufficient?", 'author_fullname': 't2_krat7nvr', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'At what point does theoretical knowledge become sufficient for practical application?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g24jqz', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1728752315.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I tend to immerse myself in theory, but I&#39;m trying to shift my approach. How much theory is sufficient?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1g24jqz', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Homo_Sapien98'), 'discussion_type': None, 'num_comments': 11, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1g24jqz/at_what_point_does_theoretical_knowledge_become/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g24jqz/at_what_point_does_theoretical_knowledge_become/', 'subreddit_subscribers': 220318, 'created_utc': 1728752315.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.059+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff96b7bbe0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': '', 'author_fullname': 't2_10v76s', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'The Dawn of the AI-Native Data Stack', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 80, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1g2clte', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.29, 'author_flair_background_color': None, 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/EAtJqNFCW2jTNcN23NnTwoPZWEghO1_cU2043_XZAXA.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'link', 'content_categories': None, 'is_self': False, 'subreddit_type': 'public', 'created': 1728775511.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'dataengineeringweekly.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://www.dataengineeringweekly.com/p/the-dawn-of-the-ai-native-data-stack', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/NOhyhBHDDcM20CHGqXA52iXSHugx2ATfelKHE49mklk.jpg?auto=webp&s=7174c2b6b40ae28a35aedffce28fda941b9a0d7a', 'width': 768, 'height': 439}, 'resolutions': [{'url': 'https://external-preview.redd.it/NOhyhBHDDcM20CHGqXA52iXSHugx2ATfelKHE49mklk.jpg?width=108&crop=smart&auto=webp&s=7a73c86602918828822cc1bd6db0858d238264dc', 'width': 108, 'height': 61}, {'url': 'https://external-preview.redd.it/NOhyhBHDDcM20CHGqXA52iXSHugx2ATfelKHE49mklk.jpg?width=216&crop=smart&auto=webp&s=2840d8f45263ed1a1f0cfcbb4a251d5a6efa1540', 'width': 216, 'height': 123}, {'url': 'https://external-preview.redd.it/NOhyhBHDDcM20CHGqXA52iXSHugx2ATfelKHE49mklk.jpg?width=320&crop=smart&auto=webp&s=3c93c436e41da4fe844346dde437e125001d00a8', 'width': 320, 'height': 182}, {'url': 'https://external-preview.redd.it/NOhyhBHDDcM20CHGqXA52iXSHugx2ATfelKHE49mklk.jpg?width=640&crop=smart&auto=webp&s=943555142a1a0f0d5ecf815760e93c14aecbad03', 'width': 640, 'height': 365}], 'variants': {}, 'id': 'XbgOgFRG8_g8XjeD-uS9LC3h7P-KQtiIeHNOJKKIShA'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'mod_note': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'num_reports': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1g2clte', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='vananth22'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1g2clte/the_dawn_of_the_ainative_data_stack/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.dataengineeringweekly.com/p/the-dawn-of-the-ai-native-data-stack', 'subreddit_subscribers': 220318, 'created_utc': 1728775511.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-10-13T13:00:41.059+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-10-13T13:00:41.067+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=etl_reddit_pipeline, task_id=reddit_extraction, execution_date=20241013T130038, start_date=20241013T130039, end_date=20241013T130041
[2024-10-13T13:00:41.104+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-10-13T13:00:41.116+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
